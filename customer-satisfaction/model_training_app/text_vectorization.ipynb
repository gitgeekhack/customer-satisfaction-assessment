{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554ed050-f211-40ec-8481-de846ed4f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf5983d-e8cb-4da4-991b-ac686dd95627",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_conversation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c117e7-bd3c-4fd9-b8da-e9f8448c5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (183, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>rm_stopwords</th>\n",
       "      <th>stemma_nltk_message</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8b8c697f82ce40e4a04138383676ef5a</td>\n",
       "      <td>2021-07-28T19:12:56.844000+00:00</td>\n",
       "      <td>Bot</td>\n",
       "      <td>['Hi', 'I', 'am', 'Srijan', 'Chat', 'Bot.', 'W...</td>\n",
       "      <td>hi srijan chat bot. welcome srijan.</td>\n",
       "      <td>hi i am srijan chat bot. welcom to srijan.</td>\n",
       "      <td>hi I be srijan chat bot welcome to srijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8b8c697f82ce40e4a04138383676ef5a</td>\n",
       "      <td>2021-07-28T19:12:56.845000+00:00</td>\n",
       "      <td>Bot</td>\n",
       "      <td>['What', 'can', 'I', 'help', 'you', 'with', 't...</td>\n",
       "      <td>help today</td>\n",
       "      <td>what can i help you with today</td>\n",
       "      <td>what can I help you with today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8b8c697f82ce40e4a04138383676ef5a</td>\n",
       "      <td>2021-07-28T19:13:13.712000+00:00</td>\n",
       "      <td>Customer</td>\n",
       "      <td>['Property', 'Requirement']</td>\n",
       "      <td>property requirement</td>\n",
       "      <td>properti requir</td>\n",
       "      <td>property requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b8c697f82ce40e4a04138383676ef5a</td>\n",
       "      <td>2021-07-28T19:13:13.874000+00:00</td>\n",
       "      <td>Bot</td>\n",
       "      <td>['Sure.', 'I', 'will', 'assist', 'you', 'in', ...</td>\n",
       "      <td>sure. assist shortlisting properties choice ba...</td>\n",
       "      <td>sure. i will assist you in shortlist the prope...</td>\n",
       "      <td>sure I will assist you in shortlist the proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b8c697f82ce40e4a04138383676ef5a</td>\n",
       "      <td>2021-07-28T19:13:13.875000+00:00</td>\n",
       "      <td>Bot</td>\n",
       "      <td>['Let', 's', 'start', 'with', 'your', 'name.']</td>\n",
       "      <td>let start name.</td>\n",
       "      <td>let s start with your name.</td>\n",
       "      <td>let us start with your name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          thread_id                        created_at  \\\n",
       "0  8b8c697f82ce40e4a04138383676ef5a  2021-07-28T19:12:56.844000+00:00   \n",
       "1  8b8c697f82ce40e4a04138383676ef5a  2021-07-28T19:12:56.845000+00:00   \n",
       "2  8b8c697f82ce40e4a04138383676ef5a  2021-07-28T19:13:13.712000+00:00   \n",
       "3  8b8c697f82ce40e4a04138383676ef5a  2021-07-28T19:13:13.874000+00:00   \n",
       "4  8b8c697f82ce40e4a04138383676ef5a  2021-07-28T19:13:13.875000+00:00   \n",
       "\n",
       "  created_by                                          tokenized  \\\n",
       "0        Bot  ['Hi', 'I', 'am', 'Srijan', 'Chat', 'Bot.', 'W...   \n",
       "1        Bot  ['What', 'can', 'I', 'help', 'you', 'with', 't...   \n",
       "2   Customer                        ['Property', 'Requirement']   \n",
       "3        Bot  ['Sure.', 'I', 'will', 'assist', 'you', 'in', ...   \n",
       "4        Bot     ['Let', 's', 'start', 'with', 'your', 'name.']   \n",
       "\n",
       "                                        rm_stopwords  \\\n",
       "0                hi srijan chat bot. welcome srijan.   \n",
       "1                                         help today   \n",
       "2                               property requirement   \n",
       "3  sure. assist shortlisting properties choice ba...   \n",
       "4                                    let start name.   \n",
       "\n",
       "                                 stemma_nltk_message  \\\n",
       "0         hi i am srijan chat bot. welcom to srijan.   \n",
       "1                     what can i help you with today   \n",
       "2                                    properti requir   \n",
       "3  sure. i will assist you in shortlist the prope...   \n",
       "4                        let s start with your name.   \n",
       "\n",
       "                                               lemma  \n",
       "0          hi I be srijan chat bot welcome to srijan  \n",
       "1                     what can I help you with today  \n",
       "2                               property requirement  \n",
       "3  sure I will assist you in shortlist the proper...  \n",
       "4                        let us start with your name  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape : {}\".format(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad028b37-88db-4d56-a037-c6a8c439a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract message field and convert message field into list\n",
    "messages = list(data['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde21205-b75e-4d6e-bc55-3d8236e89a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data['message'][84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c54908-83c1-4e88-9141-e3b210d3b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7f6a4-56f5-4693-8202-01c93df76648",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f6894-7843-4567-a792-06ae59fbee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    text = re.sub('[^a-zA-Z0-9(+*) \\n\\.]', ' ', temp[i])\n",
    "    # text = tp[i]\n",
    "    print(\"{} -> {}\".format(i, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a6fef-bf72-4f8b-8a77-1d8d647e8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4da6a-261f-4705-aa76-6e7d8a5cff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3289330-54fe-49ed-a3e6-7115477adfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sent, min_count=1, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44685a94-1c19-4652-8682-f187c14c71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = phrases[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164c55f-21f7-4849-bc66-be56261006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ace5b3-819e-4eff-896b-73d739da3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393f730-8179-4f95-a762-8b0c96ab0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee68a7-925c-47bd-9713-d080f70b0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd8d39-cee2-4c91-9fe3-3a4781000976",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=1, window=2, vector_size=100, alpha=0.03, negative=20, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e02a81-c470-4c46-98e4-5c5c24ad017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4b94c-376d-4bc7-86f7-31654874287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121aee5a-ca2e-4183-aa02-61c732732864",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(w2v_model.wv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b0245-cbdc-4c5f-9f2f-a79c5281d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.get_vector('welcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554deb8-622a-4ec1-b24b-edb3286c2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.key_to_index[\"hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cf52e9-269e-4ec9-919a-67d0995724d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe word embedding technique\n",
    "import os\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b575cf7-b50a-490a-8844-c6bb17683129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "CPU times: user 18.6 s, sys: 539 ms, total: 19.1 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt','r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    embeddings_index[word] = vector\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e7b77d-f9af-44d1-9961-3acea9d71a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_word(emmbedes):\n",
    "  nearest = sorted(embeddings_index.keys(), key=lambda word: spatial.distance.euclidean(embeddings_index[word], emmbedes))\n",
    "  return nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b79de9-a2ea-4ec9-9ff7-a45c593a76da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glad',\n",
       " 'always',\n",
       " 'wish',\n",
       " 'everyone',\n",
       " 'pleased',\n",
       " 'sure',\n",
       " 'obviously',\n",
       " 'really',\n",
       " 'everybody']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_word(embeddings_index['happy'])[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f92da4-51b2-4838-8cd8-6556e8b412f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:50:54.296038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-22 11:50:54.296072: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d8b621-936b-49b0-a2dc-4e645f16952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a859a623-63a3-41ef-9209-7cf6dd30a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3deff3b6-988b-4d45-93a7-6ad867ca218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.fit_on_texts(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8372f336-c5b7-451b-9f41-6c45dc753269",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67bbe818-c7bf-4c7c-b4e7-f5ae68a1cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2148a44-6d57-4f72-8b44-033a59e4a6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'be', 2: 'look', 3: 'the', 4: 'a', 5: 'you', 6: 'kolkata', 7: 'of', 8: 'for', 9: 'property', 10: 'on', 11: 'from', 12: 'take', 13: 'at', 14: 'location', 15: 'to', 16: '▪', 17: 'and', 18: 'km', 19: 'road', 20: 'within', 21: 'just', 22: '3', 23: 'we', 24: 'in', 25: '2', 26: 'have', 27: 'north', 28: 'project', 29: 'jessore', 30: 'residential', 31: 'which', 32: 'eterni', 33: 'one', 34: 'station', 35: 'metro', 36: 'with', 37: 'bhk', 38: 'our', 39: 'what', 40: 'how', 41: 'area', 42: '●', 43: 'new', 44: 'kind', 45: 'many', 46: 'bedroom', 47: 'follow', 48: 'locate', 49: 'doltala', 50: 'more', 51: 'apartment', 52: 'back', 53: 'madhyamgram', 54: 'go', 55: 'main', 56: 'menu', 57: 'dumdum', 58: '5', 59: 'i', 60: 'most', 61: 'this', 62: '1', 63: 'eternia', 64: 'will', 65: 'name', 66: 'spread', 67: 'over', 68: 'land', 69: '6', 70: 'chowmatha', 71: 'water', 72: 'amtala', 73: 'panache', 74: 'sector', 75: 'your', 76: 'house', 77: '4bhk', 78: '345', 79: 'cottah', 80: 'good', 81: 'minute', 82: 'away', 83: 'impressive', 84: 'upcoming', 85: 'city', 86: 'south', 87: '’s', 88: 'srijan', 89: 'can', 90: 'get', 91: 'start', 92: 'number', 93: 'contact', 94: 'barrackpur', 95: 'railway', 96: 'distance', 97: 'airport', 98: '13', 99: '900', 100: 'm', 101: 'barrakpore', 102: 'surround', 103: 'an', 104: 'green', 105: 'greenfield', 106: 'near', 107: 'behala', 108: 'chowrasta', 109: 'park', 110: 'all', 111: 'here', 112: 'h', 113: 'd', 114: 'east', 115: 'it', 116: 'help', 117: 'would', 118: 'let', 119: 'eternis', 120: 'price', 121: '3bhk', 122: 'by', 123: 'badu', 124: 'body', 125: 'rise', 126: 'phase', 127: 'prestigious', 128: 'month', 129: 'grace', 130: 'period', 131: 'mahisbathan', 132: 'behind', 133: 'edge', 134: 'happen', 135: 'v', 136: 'salt', 137: 'lake', 138: 'open', 139: 'design', 140: 'please', 141: 'email', 142: 'like', 143: 'know', 144: 'first', 145: 'us', 146: 'deb', 147: 'that', 148: 'lovely', 149: 'phone', 150: '919593526602', 151: 'flat', 152: 'rs', 153: 'lac', 154: 'onwards', 155: 'imagine', 156: 'vibrant', 157: 'life', 158: 'quiet', 159: 'foot', 160: 'print', 161: 'nature', 162: 'opposite', 163: 'nsg', 164: 'hub', 165: 'urban', 166: 'live', 167: 'habitat', 168: 'engulf', 169: 'byacre', 170: 'paradise', 171: 'native', 172: 'bird', 173: 'regional', 174: 'tree', 175: 'large', 176: 'natural', 177: 'locality', 178: 'simple', 179: 'walk', 180: 'round', 181: 'place', 182: 'quaint', 183: 'fiction', 184: 'limited', 185: 'housing', 186: '9', 187: 'nearby', 188: 'bank', 189: 'branch', 190: 'about', 191: 'central', 192: 'swapnopuron', 193: 'swapno', 194: 'puron', 195: 'every', 196: 'space', 197: 'facility', 198: 'floor', 199: 'view', 200: 'available', 201: 'size', 202: 'plan', 203: 'image', 204: 'possession', 205: 'condo', 206: 'till', 207: 'date', 208: 'resplendent', 209: 'rendezvous', 210: 'vaastu', 211: 'compliant', 212: 'least', 213: 'three', 214: 'side', 215: 'elevation', 216: 'exude', 217: 'positive', 218: 'uplifting', 219: 'feel', 220: 'head', 221: 'shoulder', 222: 'above', 223: 'ambient', 224: 'skyline', 225: 'district', 226: 'bring', 227: 'together', 228: 'some', 229: 'fine', 230: 'consultant', 231: 'business', 232: '000', 233: 'advisor', 234: 'already', 235: 'could', 236: 'also', 237: 'share', 238: 'yours', 239: 'send', 240: 'detail', 241: 'snehansu', 242: 'sen', 243: 'commercial', 244: 'hi', 245: 'chat', 246: 'bot', 247: 'welcome', 248: 'today', 249: 'requirement', 250: 'sure', 251: 'assist', 252: 'shortlist', 253: 'choice', 254: 'base', 255: 'few', 256: 'question', 257: 'richa', 258: '48', 259: 'llp', 260: 'liability', 261: 'partnership', 262: 'between', 263: 'bengal', 264: 'development', 265: 'company', 266: 'limit', 267: 'bghdcl', 268: 'realty', 269: 'private', 270: 'srpl', 271: 'jote', 272: 'sibrampur', 273: 'west', 274: 'soar', 275: 'skyward', 276: 'luxurious', 277: 'high', 278: 'shibrampur', 279: '4', 280: 'mahanayak', 281: 'uttam', 282: 'kumar', 283: 'shakuntala', 284: 'bus', 285: 'stand', 286: 'super', 287: 'market', 288: 'bazaar', 289: 'major', 290: 'their', 291: 'operate', 292: 'atm', 293: 'multiplex', 294: 'ajanta', 295: 'cinema', 296: 'pricing', 297: '58', 298: '8', 299: 'bigha', 300: 'approx', 301: 'gate', 302: 'community', 303: 'renowned', 304: 'developer', 305: 'star', 306: 'group', 307: 'embody', 308: 'joy', 309: 'comfort', 310: 'infuse', 311: 'spirit', 312: 'celebration', 313: '300', 314: '11', 315: 'block', 316: 'g', 317: 'enough', 318: 'splendid', 319: 'modern', 320: 'amenity', 321: 'sunny', 322: 'beside', 323: 'sbi', 324: 'hdfc', 325: 'click', 326: 'check', 327: 'unit', 328: '754', 329: 'sqft', 330: 'june', 331: '2019', 332: 'ii', 333: 'mid', 334: '2020', 335: 'july', 336: '2018', 337: '6th', 338: 'why', 339: 'tall', 340: 'marvel', 341: 'neighbourhood', 342: 'infinite', 343: 'acre', 344: 'wetland', 345: '28', 346: 'sq', 347: 'ft', 348: 'clubhouse', 349: 'wide', 350: 'manicure', 351: 'walkway', 352: 'naturally', 353: 'light', 354: 'surrounding', 355: 'funnel', 356: 'shape', 357: 'architecture', 358: 'ample', 359: 'wind', 360: 'circulation', 361: 'gallery', 362: 'below', 363: 'else', 364: 'call', 365: 'great', 366: 'happy', 367: 'no', 368: 'later', 369: 'enter', 370: 'valid', 371: 'address', 372: 'interested', 373: 'logistics', 374: 'under', 375: 'logistic', 376: 'shopping', 377: 'mall', 378: 'hospitality', 379: 'schedule', 380: 'visit', 381: 'callback', 382: 'state', 383: 'art', 384: 'experience', 385: 'centre', 386: 'show', 387: 'everything', 388: 'may', 389: 'want', 390: 'there'}\n"
     ]
    }
   ],
   "source": [
    "print(tokens.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721f1f98-cfe4-4553-8f82-e6573f9cc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokens.texts_to_sequences(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "417151b3-dae7-467d-a49c-2e5124c45a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[244, 59, 1, 88, 245, 246, 247, 15, 88]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd152183-6aa2-4079-94f3-2ca3daf36374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29742612-ac41-4703-986c-5a8c40546d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 120\n",
    "x = pad_sequences(encoded_text, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b5f393-78f0-41f9-9964-8d6b08c47ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▪\n",
      "eterni\n",
      "●\n",
      "doltala\n",
      "chowmatha\n",
      "amtala\n",
      "4bhk\n",
      "cottah\n",
      "srijan\n",
      "barrackpur\n",
      "barrakpore\n",
      "eternis\n",
      "3bhk\n",
      "mahisbathan\n",
      "919593526602\n",
      "byacre\n",
      "swapnopuron\n",
      "swapno\n",
      "puron\n",
      "snehansu\n",
      "bghdcl\n",
      "srpl\n",
      "sibrampur\n",
      "shibrampur\n",
      "mahanayak\n"
     ]
    }
   ],
   "source": [
    "word_vector_matrix = np.zeros((vocab_size+1, 200))\n",
    "\n",
    "for word, index in tokens.word_index.items():\n",
    "    vector = embeddings_index.get(word)\n",
    "    if vector is not None:\n",
    "        word_vector_matrix[index] = vector\n",
    "    else:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aeaf2-2aeb-42fa-a252-0bf61ef7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_vector_matrix[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e6abe-4e2a-4b63-afed-f5a178672c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
